ğŸ” Adilâ€™s RAG Chatbot (FAISS + Sentence Transformers + OpenAI)

Live Demo: https://huggingface.co/spaces/Adilislam00/Adil-RAG-Chatbot

A fully functional Retrieval-Augmented Generation (RAG) system that combines:

FAISS vector search

Sentence Transformers embeddings

OpenAI GPT-4o-mini

Gradio UI

Deployment on HuggingFace Spaces

This project demonstrates a production-style RAG pipeline that you can extend for research, internships, or real-world applications.

ğŸš€ Features
âœ… 1. Retrieval-Augmented Generation (RAG)

Converts your custom text corpus into embeddings

Uses FAISS to retrieve top-K similar documents

Sends retrieved docs + query to OpenAI

Ensures answers are grounded in actual context

âœ… 2. Efficient Embedding Pipeline

Lazy loading (initializes only on first request â€” fast startup)

Precomputed embedding/index support (embeddings.npy, saved_index.faiss)

âœ… 3. Clean, User-Friendly UI

Built using Gradio Blocks

Displays:

Answer

Sources used

Retrieved context

âœ… 4. Cloud Deployment

Runs completely on HuggingFace Spaces, publicly accessible.

ğŸ§  Architecture Overview
User Query
     â”‚
     â–¼
Sentence Transformers (query embedding)
     â”‚
     â–¼
FAISS Vector Search (top-K docs)
     â”‚
     â–¼
OpenAI GPT-4o-mini (answer using context)
     â”‚
     â–¼
Gradio UI (answer + sources)

ğŸ“ Project Structure
Adil-RAG-Chatbot/
â”‚
â”œâ”€â”€ app.py                 # Gradio UI
â”œâ”€â”€ requirements.txt       # Dependencies
â”‚
â””â”€â”€ core/
    â”œâ”€â”€ rag_chatbot_openai.py     # RAG engine
    â”œâ”€â”€ rag_basic.py              # (optional test script)
    â”œâ”€â”€ corpus.txt                # Your knowledge base
    â”œâ”€â”€ embeddings.npy            # (optional) precomputed embeddings
    â””â”€â”€ saved_index.faiss         # (optional) FAISS index

ğŸ› ï¸ Technologies Used

Python 3.10+

FAISS (CPU)

Sentence Transformers (all-MiniLM-L6-v2)

OpenAI Chat Completions API

NumPy

Gradio

HuggingFace Spaces

ğŸ§© How Retrieval Works

Convert corpus sentences into 384-dimensional embeddings

Build FAISS index

Convert user query into embedding

FAISS retrieves top-k most similar documents

Construct prompt using retrieved docs

OpenAI model generates grounded, citation-supported answer

ğŸ–¥ï¸ Running Locally
1. Clone repo
git clone https://github.com/Adilislam0/ML-
cd ML-/RAG

2. Create virtual environment
python -m venv rag_env

3. Activate venv

Windows

rag_env\Scripts\activate

4. Install dependencies
pip install -r requirements.txt

5. Add your OpenAI key
setx OPENAI_API_KEY "sk-xxxxx"

6. Run app
python app.py

ğŸŒ Deployment (HuggingFace Spaces)
Step-1: Create a new Space

Choose Gradio template.

Step-2: Upload these files:

app.py

requirements.txt

Entire core/ folder

Step-3: Add your secret key

Settings â†’ Variables and Secrets

OPENAI_API_KEY = sk-xxxxxx

Step-4: Space will auto-build

Your live RAG app becomes available instantly.

ğŸ§ª Example Query

Q: What is gradient descent?
A: â€œGradient descent is an optimization algorithm used to minimize loss functionsâ€¦â€
Sources: Doc 1, Doc 2, â€¦

ğŸ’¼ Add to Resume

Retrieval-Augmented Generation Chatbot (FAISS + OpenAI + HF Spaces)
Built a production-grade RAG system using FAISS vector search, Sentence Transformers, and OpenAI APIs.
Optimized startup latency with lazy initialization and precomputed embeddings.
Deployed full-stack ML application using Gradio on HuggingFace Spaces.

ğŸ“ˆ Future Improvements

Chunking long documents

Metadata-enhanced retrieval

Reranking using cross encoder

Chat history memory

Streaming answers

Vector DB migration (Chroma / Pinecone / Qdrant)

ğŸ‘¨â€ğŸ’» Author

Aadil Islam
MTech Artificial Intelligence
